# Benchmarks: PyTorchÂ â†’Â StableHLOÂ â†’Â IREE

A **reproducible microâ€‘benchmark suite** for testing how common PyTorch models compile and run across multiple backâ€‘ends (CPU, CUDA, Vulkan, ROCm) using the OpenXLAÂ /Â IREE toolchain.

---

## ğŸ“ Repository layout

```text
benchmarks/
â”œâ”€â”€ env/                 # Preâ€‘baked Conda env specs (pick one)
â”‚Â Â  â”œâ”€â”€ torch-stablehlo.yaml        # PyTorchÂ +Â StableHLO (CPU)
â”‚Â Â  â”œâ”€â”€ torch-stablehlo-gpu.yaml    # PyTorchÂ +Â StableHLO (CUDA)
â”‚Â Â  â””â”€â”€ stablehlo-iree.yaml         # Standâ€‘alone StableHLO â†’ IREE toolchain
â”œâ”€â”€ models/              # Lightweight model stubs (Conv, GAT â€¦)
â”‚Â Â  â”œâ”€â”€ conv_block.py
â”‚Â Â  â”œâ”€â”€ gcn_block.py
â”‚Â Â  â”œâ”€â”€ graphsage_block.py
â”‚Â Â  â”œâ”€â”€ gat_block.py
â”‚Â Â  â””â”€â”€ gatv2_block.py
â”œâ”€â”€ scripts/             # All entryâ€‘point helpers
â”‚Â Â  â”œâ”€â”€ run_bench.py     # Pureâ€‘PyTorch latency probe
â”‚Â Â  â””â”€â”€ compile_iree.py  # PyTorchÂ â†’Â StableHLOÂ â†’Â IREE runner /// Not Working Currently
â””â”€â”€ results/             # *.vmfb, *.csv outputs are dropped here
```

---

## ğŸš€ QuickÂ start

### 1Â Â·Â Clone & create env (PythonÂ 3.11)

```bash
# clone your private repo
$ git clone git@github.com:HaeeunJeong/benchmarks-for-my-compiler.git && cd benchmarks-for-my-compiler

# conda (choose one of the YAML files)
# CPUâ€‘only example:
$ conda env create -f env/torch-stablehlo.yaml -n pt-bench
# CUDA  GPU example:
# $ conda env create -f env/torch-stablehlo-gpu.yaml -n pt-bench
$ conda activate pt-bench
```

<details>
<summary>â€¦or Docker</summary>

```bash
$ docker build -t pt-bench -f env/Dockerfile .
$ docker run --gpus all -it pt-bench /bin/bash
```

</details>

### 2Â Â·Â Run the plain PyTorch microâ€‘benchmarks

```bash
# run all models on CPU
$ python -m scripts.run_bench --device cpu --csv

# a single model on GPU
$ python -m scripts.run_bench resnet --device cuda
```

*Outputs*: perâ€‘model latency is printed and appended to `results/latency.csv` (timestamp,Â model,Â device,Â timeÂ /Â "error").

---

## ğŸ—ï¸ Supported models

| Category        | Key                 | Source                                                | Notes                                                                         |
| --------------- | ------------------- | ----------------------------------------------------- | ----------------------------------------------------------------------------- |
| SimpleÂ custom   | `conv`              | `models/conv_block.py`                                | 2Ã—ConvÂ +Â ReLU toy block used as a sanityâ€‘check kernel                         |
| **GNN**         | `gcn`\*             | `models/gcn_block.py`                                 | Graph Convolution Net                                                         |
| **GNN**         | `graphsage`\*       | PyTorchÂ Geometric                                     | GraphÂ Sage Net; The milestone of GNN model                                    |
| **GNN**         | `gat`\*             | PyTorchÂ Geometric                                     | GraphÂ AttentionÂ Net; contains `scatter_reduce`/`nonzero` (exportâ€‘unsupported) |
| **GNN**         | `gatv2`\*           | PyTorchÂ Geometric                                     | GraphÂ AttentionÂ Net; contains `scatter_reduce`/`nonzero` (exportâ€‘unsupported) |
| **CNN**         | `resnet`            | `torchvision`Â ResNetâ€‘18                               | Classic image backbone; ImageNet pretrained                                   |
| **CNN**         | `mobilenet`         | `torchvision`Â MobileNetÂ v3Â S                          | Mobileâ€‘oriented CNN; ImageNet pretrained                                      |
| **Transformer** | `vit`               | `torchvision`Â ViTâ€‘B/16                                | Vision Transformer baseline                                                   |
| **Transformer** | `bert`\*            | `bert-base-uncased`                                   | Tokenâ€‘level encoder; needs full kwargs to export                              |
| **Transformer** | `gpt2`\*            | `gpt2-xl`                                             | 1.5â€¯Bâ€‘param decoder; export kwargs WIP                                        |
| **LLM**         | `llama`\*           | `meta-llama/Llama-3.2-3B`                             | Base LlamaÂ 3.2Â 3â€¯B; compact generalâ€‘purpose LLM                               |
| **LLM**         | `llama-qlora`\*     | `meta-llama/Llama-3.2-3B-Instruct-QLORA_INT4_EO8`     | 4â€‘bit QLoRA; memoryâ€‘efficient inference                                       |
| **LLM**         | `llama-spinquant`\* | `meta-llama/Llama-3.2-3B-Instruct-SpinQuant_INT4_EO8` | 4â€‘bitÂ SpinQuant; alt quantization scheme                                      |
| **LLM**         | `deepseek`\*        | `DeepSeekâ€‘R1â€‘Distillâ€‘Qwen`                            | Distilled mathâ€‘centric LLM; complex TF graph                                  |

<sup>\*Â asterisked entries are currently skipped in `compile_iree.py` (seeÂ `UNSUPPORTED`).</sup>
<sup>\*Â marked entries are currently skipped in compile\_iree.py (seeÂ `UNSUPPORTED`).</sup>

---

## ğŸ”§ Compiling & running with IREE

```bash
# compile all supported vision models to LLVMâ€‘CPU & store vmfb
$ python -m scripts.compile_iree --target llvm-cpu --csv

# pick a specific model & CUDA backâ€‘end (needs GPU + CUDA driver)
$ python -m scripts.compile_iree resnet mobilenet --target cuda
```

*Outputs*

* **FlatBuffer (`.vmfb`)**: saved to `results/<model>-<target>.vmfb`
* **Latency CSV**: appended to `results/iree_latency.csv` with status `timeÂ (ms)`Â /Â `error`Â /Â `unsupported`.

---

## â• Adding new models

1. Drop a new Python module under `models/`, e.g. `my_model.py`.
2. Expose `(model, dummy_input)` via a helper (see existing examples).
3. Add its key to `scripts/run_bench.py` â†’ `load_model()` and to `ALL_MODELS`.
4. If the model exports cleanly to StableHLO, remove it from `UNSUPPORTED` in `compile_iree.py`.

---

## ğŸ› ï¸ Troubleshooting

| Symptom                                           | Fix                                                                                                 |
| ------------------------------------------------- | --------------------------------------------------------------------------------------------------- |
| `UserWarning: 'pretrained' is deprecated`         | TorchVision â‰¥0.13 uses `weights=..._Weights.DEFAULT`; already handled.                              |
| `This model contains ops not capturable ...`      | Operation not yet supported by Torchâ€‘XLA; keep model in `UNSUPPORTED` or write a Torchâ€‘FX fallback. |
| `treespec.unflatten` during export                | Provide full kwargs (`attention_mask`, etc.) matching the modelâ€™s forward signature.                |
| `expected operation name in quotes` at IREE stage | Ensure you pass **the actual MLIR string**, not a Python repr (use `str(shlo.mlir_module)`).        |

---

## ğŸ“œ License / visibility

This is a **private** research benchmark. Do **NOT** publish benchmark numbers externally without permission.

